<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="https://1kunn.github.io/atom.xml" rel="self"/>
  
  <link href="https://1kunn.github.io/"/>
  <updated>2024-07-24T09:44:18.417Z</updated>
  <id>https://1kunn.github.io/</id>
  
  <author>
    <name>HRW</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>顶刊翻译</title>
    <link href="https://1kunn.github.io/2024/07/23/%E9%A1%B6%E5%88%8A%E7%BF%BB%E8%AF%91/"/>
    <id>https://1kunn.github.io/2024/07/23/%E9%A1%B6%E5%88%8A%E7%BF%BB%E8%AF%91/</id>
    <published>2024-07-22T23:09:57.000Z</published>
    <updated>2024-07-24T09:44:18.417Z</updated>
    
    <content type="html"><![CDATA[<h1 id="需求如下"><a href="#需求如下" class="headerlink" title="需求如下"></a>需求如下</h1><img src="C:\Users\huangruiwen\AppData\Roaming\Typora\typora-user-images\image-20240723071053125.png" style="zoom:80%;" /><h2 id="顶刊选择"><a href="#顶刊选择" class="headerlink" title="顶刊选择"></a>顶刊选择</h2><ul><li><p>基本上中科院1区的都是顶刊</p></li><li><p>Xmol中有分类 如图<img src="F:\Typora图\image-20240723073704311.png" alt="image-20240723073704311"></p></li></ul><h2 id="中文科技论文格式"><a href="#中文科技论文格式" class="headerlink" title="中文科技论文格式"></a>中文科技论文格式</h2><p>1、字体和字号<br>论文题目：二号黑体，居中<br>各章标题：小二号黑体，居左<br>各节一级标题：小三号黑体，居左<br>各节二级标题：四号黑体，居左<br>各节三级标题：小四号黑体，居左<br>正文：小四号宋体</p><p>2、行距：正文为1.5倍行距，段前、段后无空行，各段落首行缩进2字符</p><h1 id="复制粘贴闹麻了"><a href="#复制粘贴闹麻了" class="headerlink" title="复制粘贴闹麻了"></a>复制粘贴闹麻了</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;需求如下&quot;&gt;&lt;a href=&quot;#需求如下&quot; class=&quot;headerlink&quot; title=&quot;需求如下&quot;&gt;&lt;/a&gt;需求如下&lt;/h1&gt;&lt;img src=&quot;C:&#92;Users&#92;huangruiwen&#92;AppData&#92;Roaming&#92;Typora&#92;typora-user</summary>
      
    
    
    
    
    <category term="论文" scheme="https://1kunn.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>小土堆pytorch</title>
    <link href="https://1kunn.github.io/2024/07/22/%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch/"/>
    <id>https://1kunn.github.io/2024/07/22/%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch/</id>
    <published>2024-07-22T12:18:28.000Z</published>
    <updated>2024-08-04T02:17:17.981Z</updated>
    
    <content type="html"><![CDATA[<h1 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h1><h2 id="视频链接："><a href="#视频链接：" class="headerlink" title="视频链接："></a>视频链接：</h2><p><a href="https://www.bilibili.com/video/BV1hE411t7RN/?p=8&spm_id_from=333.880.my_history.page.click&vd_source=49378ece86ab83ee76bcaac1cc96562c">https://www.bilibili.com/video/BV1hE411t7RN/?p=8&amp;spm_id_from=333.880.my_history.page.click&amp;vd_source=49378ece86ab83ee76bcaac1cc96562c</a></p><p>其他代码 数据集等链接在视频详情页</p><p>2024.7.20实测仍能使用</p><h1 id="TensorBoard的使用（一）"><a href="#TensorBoard的使用（一）" class="headerlink" title="TensorBoard的使用（一）"></a>TensorBoard的使用（一）</h1><ul><li><p>python3.6环境</p></li><li><p>代码（仅仅是构建的框架 构建y&#x3D;x的图）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="comment">#引入summarywriter工具 按住ctrl可以查看包的说明</span></span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;logs&#x27;</span>) <span class="comment">#指的是对应内容存储到logs文件夹下</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># writer.add_image()</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;y=x&#x27;</span>, i, i) <span class="comment">#参数分别是 标题 y轴 x轴</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=learn/logs --port=<span class="number">6007</span> <span class="comment">#控制台打开在6007端口处 环境要安装tensorboard  learn/logs是文件的相对路径 图像如下图所示</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="C:\Users\huangruiwen\AppData\Roaming\Typora\typora-user-images\image-20240722214624078.png" alt="image-20240722214624078"></p><h1 id="TensorBoard的使用（二）"><a href="#TensorBoard的使用（二）" class="headerlink" title="TensorBoard的使用（二）"></a>TensorBoard的使用（二）</h1><p>writer.add_image需要str numpy.array等数据型 可以在说明中看到</p><p>路径要绝对路径才生效 我也不懂为啥</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="comment">#引入summarywriter工具 按住ctrl可以查看包的说明</span></span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;logs&#x27;</span>) <span class="comment">#指的是对应内容存储到logs文件夹下</span></span><br><span class="line"></span><br><span class="line">image_path = <span class="string">&quot;D:\\program\\Anaconda3\\envs\\tf-gpu1\\learn\\data\\train\\ants_image\\0013035.jpg&quot;</span> <span class="comment">#图片路径</span></span><br><span class="line">img_PIL = Image.<span class="built_in">open</span>(image_path) <span class="comment">#打开图片</span></span><br><span class="line">img_array = np.array(img_PIL) <span class="comment">#数据类型转换 因为writer.add_image()数据类型要求</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">writer.add_image(<span class="string">&quot;test&quot;</span>, img_array, dataformats=<span class="string">&#x27;HWC&#x27;</span>) <span class="comment">#参数分别是 标题 要打开的数据 第三个我也不懂</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;y=x&#x27;</span>, i, i) <span class="comment">#参数分别是 标题 y轴 x轴</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><h2 id="效果如下"><a href="#效果如下" class="headerlink" title="效果如下"></a>效果如下</h2><p><img src="F:\Typora图\image-20240725085924903.png" alt="image-20240725085924903"></p><h1 id="transforms的使用"><a href="#transforms的使用" class="headerlink" title="transforms的使用"></a>transforms的使用</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># python的用法 -&gt; tensor数据类型</span></span><br><span class="line"><span class="comment">#通过transforms。ToTensor了解 transforms如何使用</span></span><br><span class="line"></span><br><span class="line">img_path = <span class="string">&quot;D:\\program\\Anaconda3\\envs\\tf-gpu1\\dataset\\train\\ants\\5650366_e22b7e1065.jpg&quot;</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(img_path) <span class="comment">#打开图片</span></span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#1 如何使用</span></span><br><span class="line">tensor_trans = transforms.ToTensor() <span class="comment">#先自己创建一个工具tensor_trans 返回Totensor类型的数据 因为工具包需要</span></span><br><span class="line">tensor_img = tensor_trans(img) <span class="comment">#通过创造出的工具转化数据类型</span></span><br><span class="line"></span><br><span class="line">writer.add_image(<span class="string">&quot;Tensor_img&quot;</span>, tensor_img)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><h1 id="常见的transforms"><a href="#常见的transforms" class="headerlink" title="常见的transforms"></a>常见的transforms</h1><p>简单记录下 使用还得后面多实践</p><p>使用方法都类似 要关注数据类型转变</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&quot;D:\\program\\Anaconda3\\envs\\tf-gpu1\\images\\8561027.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#ToTensor用法</span></span><br><span class="line">trans_totensor = transforms.ToTensor()</span><br><span class="line">img_tensor = trans_totensor(img)</span><br><span class="line">writer.add_image(<span class="string">&quot;ToTensor&quot;</span>, img_tensor)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Normalize归一化 改颜色的</span></span><br><span class="line">trans_norm = transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>],[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">img_norm = trans_norm(img_tensor)</span><br><span class="line">writer.add_image(<span class="string">&quot;Normalize&quot;</span>, img_norm)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Resize 改规格</span></span><br><span class="line">trans_resize = transforms.Resize((<span class="number">512</span>, <span class="number">512</span>)) <span class="comment">#img PIL -&gt; resize -&gt;img_resize PIL</span></span><br><span class="line">img_resize = trans_resize(img) <span class="comment">#img_resize PIL -&gt; totensor -&gt; img_resize</span></span><br><span class="line">img_resize = trans_totensor(img_resize)</span><br><span class="line">writer.add_image(<span class="string">&quot;Resize&quot;</span>, img_resize, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Compose -resize 也是改规格 要关注输入输出数据类型</span></span><br><span class="line">trans_resize_2 = transforms.Resize(<span class="number">512</span>)</span><br><span class="line"><span class="comment"># PIL -&gt; PIL -&gt; tensor</span></span><br><span class="line">trans_compose = transforms.Compose([trans_resize_2, trans_totensor]) <span class="comment">#compose()中参数要一个列表 所以用trans_totensor转换数据类型</span></span><br><span class="line">img_resize_2 =trans_compose(img)</span><br><span class="line">writer.add_image(<span class="string">&quot;Resize&quot;</span>, img_resize_2, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#RandomCrop 随机裁剪</span></span><br><span class="line">trans_random = transforms.RandomCrop(<span class="number">512</span>)</span><br><span class="line">trans_compose_2 = transforms.Compose([trans_random, trans_totensor])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):  <span class="comment">#随机裁剪10个</span></span><br><span class="line">    img_crop = trans_compose_2(img)</span><br><span class="line">    writer.add_image(<span class="string">&quot;RandomCrop&quot;</span>, img_crop, i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><h1 id="torchvision中的数据集使用"><a href="#torchvision中的数据集使用" class="headerlink" title="torchvision中的数据集使用"></a>torchvision中的数据集使用</h1><p><img src="F:\Typora图\image-20240728085901802-17221283448361.png" alt="image-20240728085901802"></p><p>pytorch官网这里能找到官方数据集下载</p><p>数据集下载</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./dataset&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>) <span class="comment">#调用数据集 参数：存放路径 是否是训练数据集 是否下载</span></span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./dataset&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>) <span class="comment">#测试数据集 只需要调整train为False</span></span><br></pre></td></tr></table></figure><p>数据集下载会到这</p><p><img src="F:\Typora图\image-20240728104958162-17221349999463.png" alt="image-20240728104958162"></p><p>数据集使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment">#transform的调用 有点像c里的函数</span></span><br><span class="line">dataset_transform = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.ToTensor()<span class="comment">#转成totensor</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./dataset&#x27;</span>, train=<span class="literal">True</span>, transform=dataset_transform, download=<span class="literal">True</span>) <span class="comment">#调用数据集 参数：存放路径 是否是训练数据集 是否下载</span></span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./dataset&#x27;</span>, train=<span class="literal">False</span>, transform=dataset_transform, download=<span class="literal">True</span>) <span class="comment">#测试数据集 只需要调整train为False</span></span><br><span class="line"><span class="comment">#运行后所有数据都转为totensor型</span></span><br><span class="line"><span class="comment">#第三个参数就是调用transform</span></span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;p10&#x27;</span>)<span class="comment">#保存</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):  <span class="comment">#显示前10张</span></span><br><span class="line">    img, target = test_set[i]</span><br><span class="line">    writer.add_image(<span class="string">&#x27;test_set&#x27;</span>, img, i) <span class="comment">#标签 tensor数据的图片 下标</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><h1 id="DataLoader的使用"><a href="#DataLoader的使用" class="headerlink" title="DataLoader的使用"></a>DataLoader的使用</h1><p>相比datase dataloader会把数据加载</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备的测试数据集</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">test_data = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor())<span class="comment">#引入测试数据集</span></span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(dataset=test_data, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>, drop_last=<span class="literal">True</span>)<span class="comment">#参数： 数据集 每次取4个打包</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试数据集中第一张图片及target</span></span><br><span class="line">img, target = test_data[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(img.shape)</span><br><span class="line"><span class="built_in">print</span>(target)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;dataloader&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    step = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">        imgs, targets = data</span><br><span class="line">        <span class="comment"># print(imgs.shape)</span></span><br><span class="line">        <span class="comment"># print(targets)</span></span><br><span class="line">        writer.add_images(<span class="string">&quot;Epoch: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch), imgs, step)  <span class="comment">#参数： 命名 img 步进</span></span><br><span class="line">        step = step + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>效果：</p><p><img src="F:\Typora图\image-20240729102408512-17222198505101.png" alt="image-20240729102408512"></p><h1 id="神经网络各层次"><a href="#神经网络各层次" class="headerlink" title="神经网络各层次"></a>神经网络各层次</h1><h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><p>有些超纲 看不懂 各项参数设置还得看官方文档 真要用的时候再了解</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tudui</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Tudui, <span class="variable language_">self</span>).__init__() <span class="comment">#父类初始化</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">6</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>) <span class="comment">#卷积层设置</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>): <span class="comment">#输出</span></span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">tudui = Tudui()</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;../logs&quot;</span>)</span><br><span class="line"></span><br><span class="line">step = <span class="number">0</span> <span class="comment">#步进</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    output = tudui(imgs)</span><br><span class="line">    <span class="built_in">print</span>(imgs.shape)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line">    <span class="comment"># torch.Size([64, 3, 32, 32])</span></span><br><span class="line">    writer.add_images(<span class="string">&quot;input&quot;</span>, imgs, step) <span class="comment">#看变化</span></span><br><span class="line">    <span class="comment"># torch.Size([64, 6, 30, 30])  -&gt; [xxx, 3, 30, 30]</span></span><br><span class="line"></span><br><span class="line">    output = torch.reshape(output, (-<span class="number">1</span>, <span class="number">3</span>, <span class="number">30</span>, <span class="number">30</span>)) <span class="comment">#尺寸变化 因为原尺寸无法显示</span></span><br><span class="line">    writer.add_images(<span class="string">&quot;output&quot;</span>, output, step) <span class="comment">#看变化</span></span><br><span class="line"></span><br><span class="line">    step = step + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="最大池化层（下采样）"><a href="#最大池化层（下采样）" class="headerlink" title="最大池化层（下采样）"></a>最大池化层（下采样）</h2><p>为了在保留特征的前提下缩小输入数据大小</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> MaxPool2d</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;../data&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                       transform=torchvision.transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tudui</span>(nn.Module): <span class="comment">#初始化神经网络</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Tudui, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.maxpool1 = MaxPool2d(kernel_size=<span class="number">3</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        output = <span class="variable language_">self</span>.maxpool1(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">tudui = Tudui()</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;../logs_maxpool&quot;</span>)</span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    writer.add_images(<span class="string">&quot;input&quot;</span>, imgs, step)</span><br><span class="line">    output = tudui(imgs)</span><br><span class="line">    writer.add_images(<span class="string">&quot;output&quot;</span>, output, step)</span><br><span class="line">    step = step + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><h2 id="非线性激活"><a href="#非线性激活" class="headerlink" title="非线性激活"></a>非线性激活</h2><p>ReLu Sigmoid 那些</p><h1 id="神经网络搭建实战（CIFAR10）"><a href="#神经网络搭建实战（CIFAR10）" class="headerlink" title="神经网络搭建实战（CIFAR10）"></a>神经网络搭建实战（CIFAR10）</h1><p>CIFAR10结构</p><p><img src="F:\Typora图\image-20240729104118826-17222208838803.png" alt="image-20240729104118826"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tudui</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Tudui, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.model1 = Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )   <span class="comment">#导入各层结构 具体数值设置看视频推演 很有用</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x <span class="comment">#输出结果</span></span><br><span class="line"></span><br><span class="line">tudui = Tudui()</span><br><span class="line"><span class="built_in">print</span>(tudui)</span><br><span class="line"><span class="built_in">input</span> = torch.ones((<span class="number">64</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">output = tudui(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;../logs_seq&quot;</span>)</span><br><span class="line">writer.add_graph(tudui, <span class="built_in">input</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><h1 id="现有网络模型的使用及修改"><a href="#现有网络模型的使用及修改" class="headerlink" title="现有网络模型的使用及修改"></a>现有网络模型的使用及修改</h1><p>pytorch官网</p><p><img src="F:\Typora图\image-20240730152627846-17223243907721.png" alt="image-20240730152627846"></p><h1 id="网络模型的保存和加载"><a href="#网络模型的保存和加载" class="headerlink" title="网络模型的保存和加载"></a>网络模型的保存和加载</h1><p>不同的保存方式要用不同的加载方式</p><p>保存代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 保存方式1,模型结构+模型参数（保存了两个东西）</span></span><br><span class="line">torch.save(vgg16, <span class="string">&quot;vgg16_method1.pth&quot;</span>) <span class="comment">#命名  保存路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存方式2，模型参数（官方推荐 只保存模型参数）</span></span><br><span class="line">torch.save(vgg16.state_dict(), <span class="string">&quot;vgg16_method2.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 陷阱</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tudui</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Tudui, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">tudui = Tudui()</span><br><span class="line">torch.save(tudui, <span class="string">&quot;tudui_method1.pth&quot;</span>)</span><br></pre></td></tr></table></figure><p>加载代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> model_save <span class="keyword">import</span> *</span><br><span class="line"><span class="comment"># 方式1-》保存方式1，加载模型</span></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">model = torch.load(<span class="string">&quot;vgg16_method1.pth&quot;</span>)</span><br><span class="line"><span class="comment"># print(model)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式2，加载模型 对应的保存方式对应的加载方式</span></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line">vgg16.load_state_dict(torch.load(<span class="string">&quot;vgg16_method2.pth&quot;</span>))</span><br><span class="line"><span class="comment"># model = torch.load(&quot;vgg16_method2.pth&quot;)</span></span><br><span class="line"><span class="comment"># print(vgg16)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 陷阱1</span></span><br><span class="line"><span class="comment"># class Tudui(nn.Module):</span></span><br><span class="line"><span class="comment">#     def __init__(self):</span></span><br><span class="line"><span class="comment">#         super(Tudui, self).__init__()</span></span><br><span class="line"><span class="comment">#         self.conv1 = nn.Conv2d(3, 64, kernel_size=3)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     def forward(self, x):</span></span><br><span class="line"><span class="comment">#         x = self.conv1(x)</span></span><br><span class="line"><span class="comment">#         return x</span></span><br><span class="line"></span><br><span class="line">model = torch.load(<span class="string">&#x27;tudui_method1.pth&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure><h1 id="完整的模型训练套路"><a href="#完整的模型训练套路" class="headerlink" title="完整的模型训练套路"></a>完整的模型训练套路</h1><p>主代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.datasets</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> * <span class="comment">#引入model.py</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#完整的模型训练</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#准备数据集</span></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(root=<span class="string">&quot;../data&quot;</span>, train=<span class="literal">True</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">test_data = torchvision.datasets.CIFAR10(root=<span class="string">&quot;../data&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用DataLoader加载数据集</span></span><br><span class="line">train_dataloader = DataLoader(train_data, batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader = DataLoader(test_data, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">tudui = Tudui()</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># length 长度</span></span><br><span class="line">train_data_size = <span class="built_in">len</span>(train_data)</span><br><span class="line">test_data_size = <span class="built_in">len</span>(test_data)</span><br><span class="line"><span class="comment"># 如果train_data_size=10, 训练数据集的长度为：10</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练数据集的长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_data_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试数据集的长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(test_data_size))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化器</span></span><br><span class="line"><span class="comment"># learning_rate = 0.01</span></span><br><span class="line"><span class="comment"># 1e-2=1 x (10)^(-2) = 1 /100 = 0.01</span></span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line">optimizer = torch.optim.SGD(tudui.parameters(), lr=learning_rate) <span class="comment">#对哪部分进行优化 学习率</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#设置训练网络的一些参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#记录训练的次数</span></span><br><span class="line">total_train_step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#记录测试的次数</span></span><br><span class="line">total_test_step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练的轮数</span></span><br><span class="line">epoch = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加tensorboard</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;../logs_train&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line"></span><br><span class="line">    <span class="comment">#训练步骤开始</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs, targets = data <span class="comment">#取得训练数据</span></span><br><span class="line">        output = tudui(imgs) <span class="comment">#得到输出</span></span><br><span class="line">        loss = loss_fn(output, targets) <span class="comment">#看输出与实际的误差</span></span><br><span class="line">        <span class="comment">#优化器优化模型</span></span><br><span class="line">        optimizer.zero_grad() <span class="comment">#梯度清零</span></span><br><span class="line">        loss.backward() <span class="comment">#反向传播</span></span><br><span class="line">        optimizer.step() <span class="comment">#优化</span></span><br><span class="line"></span><br><span class="line">        total_train_step = total_train_step + <span class="number">1</span>  <span class="comment"># 训练次数加一</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step % <span class="number">100</span> == <span class="number">0</span>: <span class="comment">#100次训练打印一次</span></span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;训练次数：&#123;&#125;, Loss: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_train_step, loss.item()))</span><br><span class="line">            writer.add_scalar(<span class="string">&quot;train_loss&quot;</span>, loss.item(), total_train_step)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试步骤开始 为了看训练后的模型的准确性</span></span><br><span class="line">    tudui.<span class="built_in">eval</span>()</span><br><span class="line">    total_test_loss = <span class="number">0</span></span><br><span class="line">    total_accuracy = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader: <span class="comment">#取测试数据集</span></span><br><span class="line">            imgs, targets = data</span><br><span class="line">            outputs = tudui(imgs) <span class="comment">#对应的输出</span></span><br><span class="line">            loss = loss_fn(outputs, targets) <span class="comment">#比对误差</span></span><br><span class="line">            total_test_loss = total_test_loss + loss.item()</span><br><span class="line">            accuracy = (outputs.argmax(<span class="number">1</span>) == targets).<span class="built_in">sum</span>()</span><br><span class="line">            total_accuracy = total_accuracy + accuracy</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的Loss: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_test_loss))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的正确率: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_accuracy/test_data_size))</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;test_loss&quot;</span>, total_test_loss, total_test_step)</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;test_accuracy&quot;</span>, total_accuracy/test_data_size, total_test_step)</span><br><span class="line">    total_test_step = total_test_step + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    torch.save(tudui, <span class="string">&quot;tudui_&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型已保存&quot;</span>)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><p>model设置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#搭建神经网络 CIFAR10有十个类 所以神经网络要设为十分类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tudui</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Tudui, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.model = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tuidu = Tudui()</span><br><span class="line">    <span class="built_in">input</span> = torch.ones((<span class="number">64</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">    output= tuidu(<span class="built_in">input</span>)</span><br><span class="line">    <span class="built_in">print</span>((output.shape))</span><br></pre></td></tr></table></figure><h1 id="利用GPU加速"><a href="#利用GPU加速" class="headerlink" title="利用GPU加速"></a>利用GPU加速</h1><p>其实就是比cpu（上面的版本） 在模型 数据 损失函数中利用cuda进行gpu加速</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 作者：小土堆</span></span><br><span class="line"><span class="comment"># 公众号：土堆碎念</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># from model import *</span></span><br><span class="line"><span class="comment"># 准备数据集</span></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(root=<span class="string">&quot;../data&quot;</span>, train=<span class="literal">True</span>, transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                          download=<span class="literal">True</span>)</span><br><span class="line">test_data = torchvision.datasets.CIFAR10(root=<span class="string">&quot;../data&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                         download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># length 长度</span></span><br><span class="line">train_data_size = <span class="built_in">len</span>(train_data)</span><br><span class="line">test_data_size = <span class="built_in">len</span>(test_data)</span><br><span class="line"><span class="comment"># 如果train_data_size=10, 训练数据集的长度为：10</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练数据集的长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_data_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试数据集的长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(test_data_size))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用 DataLoader 来加载数据集</span></span><br><span class="line">train_dataloader = DataLoader(train_data, batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader = DataLoader(test_data, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建网络模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tudui</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Tudui, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.model = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">tudui = Tudui()</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    tudui = tudui.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    loss_fn = loss_fn.cuda()</span><br><span class="line"><span class="comment"># 优化器</span></span><br><span class="line"><span class="comment"># learning_rate = 0.01</span></span><br><span class="line"><span class="comment"># 1e-2=1 x (10)^(-2) = 1 /100 = 0.01</span></span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line">optimizer = torch.optim.SGD(tudui.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练网络的一些参数</span></span><br><span class="line"><span class="comment"># 记录训练的次数</span></span><br><span class="line">total_train_step = <span class="number">0</span></span><br><span class="line"><span class="comment"># 记录测试的次数</span></span><br><span class="line">total_test_step = <span class="number">0</span></span><br><span class="line"><span class="comment"># 训练的轮数</span></span><br><span class="line">epoch = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加tensorboard</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;../logs_train&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-------第 &#123;&#125; 轮训练开始-------&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练步骤开始</span></span><br><span class="line">    tudui.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs, targets = data</span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            imgs = imgs.cuda()</span><br><span class="line">            targets = targets.cuda()</span><br><span class="line">        outputs = tudui(imgs)</span><br><span class="line">        loss = loss_fn(outputs, targets)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 优化器优化模型</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        total_train_step = total_train_step + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;训练次数：&#123;&#125;, Loss: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_train_step, loss.item()))</span><br><span class="line">            writer.add_scalar(<span class="string">&quot;train_loss&quot;</span>, loss.item(), total_train_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 测试步骤开始</span></span><br><span class="line">    tudui.<span class="built_in">eval</span>()</span><br><span class="line">    total_test_loss = <span class="number">0</span></span><br><span class="line">    total_accuracy = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs, targets = data</span><br><span class="line">            <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">                imgs = imgs.cuda()</span><br><span class="line">                targets = targets.cuda()</span><br><span class="line">            outputs = tudui(imgs)</span><br><span class="line">            loss = loss_fn(outputs, targets)</span><br><span class="line">            total_test_loss = total_test_loss + loss.item()</span><br><span class="line">            accuracy = (outputs.argmax(<span class="number">1</span>) == targets).<span class="built_in">sum</span>()</span><br><span class="line">            total_accuracy = total_accuracy + accuracy</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的Loss: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_test_loss))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的正确率: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_accuracy/test_data_size))</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;test_loss&quot;</span>, total_test_loss, total_test_step)</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;test_accuracy&quot;</span>, total_accuracy/test_data_size, total_test_step)</span><br><span class="line">    total_test_step = total_test_step + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    torch.save(tudui, <span class="string">&quot;tudui_&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型已保存&quot;</span>)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;链接&quot;&gt;&lt;a href=&quot;#链接&quot; class=&quot;headerlink&quot; title=&quot;链接&quot;&gt;&lt;/a&gt;链接&lt;/h1&gt;&lt;h2 id=&quot;视频链接：&quot;&gt;&lt;a href=&quot;#视频链接：&quot; class=&quot;headerlink&quot; title=&quot;视频链接：&quot;&gt;&lt;/a&gt;视频链接</summary>
      
    
    
    
    
    <category term="学习记录" scheme="https://1kunn.github.io/tags/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>学习Typora</title>
    <link href="https://1kunn.github.io/2024/07/21/%E5%AD%A6%E4%B9%A0Typora/"/>
    <id>https://1kunn.github.io/2024/07/21/%E5%AD%A6%E4%B9%A0Typora/</id>
    <published>2024-07-21T01:00:08.000Z</published>
    <updated>2024-07-22T12:17:34.049Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Typora语法"><a href="#Typora语法" class="headerlink" title="Typora语法"></a>Typora语法</h1><p>#就是一级标题</p><p>##二级标题，以此类推</p><h1 id="行间公式"><a href="#行间公式" class="headerlink" title="行间公式"></a>行间公式</h1><p> 输入$$然后按回车<br>$$<br>F&#x3D;ma<br>$$</p><h1 id="列表生成"><a href="#列表生成" class="headerlink" title="列表生成"></a>列表生成</h1><p>-（横杠）和一个空格 </p><h2 id=""><a href="#" class="headerlink" title="- "></a>- </h2><p>数字和点和空格就是有序列表</p><p>1. </p><h1 id="插入代码块"><a href="#插入代码块" class="headerlink" title="插入代码块"></a>插入代码块</h1><p>3个反引号+回车</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> rang(<span class="number">5</span>):</span><br></pre></td></tr></table></figure><h1 id="插入图片-表格-都在上面格式里"><a href="#插入图片-表格-都在上面格式里" class="headerlink" title="插入图片 表格 都在上面格式里"></a>插入图片 表格 都在上面格式里</h1><h1 id="文本格式"><a href="#文本格式" class="headerlink" title="文本格式"></a>文本格式</h1><p>左右都加</p><p>加粗是两个*</p><p><strong>加粗</strong></p><p>斜体是一个*</p><p><em>斜体</em></p><p>下划线 ctrl+u</p><p><u>下划线</u></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Typora语法&quot;&gt;&lt;a href=&quot;#Typora语法&quot; class=&quot;headerlink&quot; title=&quot;Typora语法&quot;&gt;&lt;/a&gt;Typora语法&lt;/h1&gt;&lt;p&gt;#就是一级标题&lt;/p&gt;
&lt;p&gt;##二级标题，以此类推&lt;/p&gt;
&lt;h1 id=&quot;行间公式&quot;&gt;&lt;</summary>
      
    
    
    
    
    <category term="学习记录" scheme="https://1kunn.github.io/tags/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>MyfirstBlog</title>
    <link href="https://1kunn.github.io/2024/07/20/MyfirstBlog/"/>
    <id>https://1kunn.github.io/2024/07/20/MyfirstBlog/</id>
    <published>2024-07-20T12:10:48.000Z</published>
    <updated>2024-07-21T00:50:32.487Z</updated>
    
    <content type="html"><![CDATA[<h1 id="这是我的第一篇博客"><a href="#这是我的第一篇博客" class="headerlink" title="这是我的第一篇博客"></a>这是我的第一篇博客</h1><p>欢迎你！</p><p> 是我 如果我有多张船film 你会唔会同我一齐走</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;这是我的第一篇博客&quot;&gt;&lt;a href=&quot;#这是我的第一篇博客&quot; class=&quot;headerlink&quot; title=&quot;这是我的第一篇博客&quot;&gt;&lt;/a&gt;这是我的第一篇博客&lt;/h1&gt;&lt;p&gt;欢迎你！&lt;/p&gt;
&lt;p&gt; 是我 如果我有多张船film 你会唔会同我一齐走&lt;/p&gt;
</summary>
      
    
    
    
    
    <category term="tag1" scheme="https://1kunn.github.io/tags/tag1/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://1kunn.github.io/2024/07/20/hello-world/"/>
    <id>https://1kunn.github.io/2024/07/20/hello-world/</id>
    <published>2024-07-20T02:02:05.202Z</published>
    <updated>2024-07-20T02:02:05.202Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
